<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
                "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
  <title>Description of utl_searchmodel</title>
  <meta name="keywords" content="utl_searchmodel">
  <meta name="description" content="Find the best predictive model out of a parameterized set, via cross-validation.">
  <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
  <meta name="generator" content="m2html v1.5 &copy; 2003-2005 Guillaume Flandin">
  <meta name="robots" content="index, follow">
  <link type="text/css" rel="stylesheet" href="../../m2html.css">
</head>
<body>
<a name="_top"></a>
<div><a href="../../index.html">Home</a> &gt;  <a href="#">code</a> &gt; <a href="index.html">utils</a> &gt; utl_searchmodel.m</div>

<!--<table width="100%"><tr><td align="left"><a href="../../index.html"><img alt="<" border="0" src="../../left.png">&nbsp;Master index</a></td>
<td align="right"><a href="index.html">Index for code/utils&nbsp;<img alt=">" border="0" src="../../right.png"></a></td></tr></table>-->

<h1>utl_searchmodel

</h1>

<h2><a name="_name"></a>PURPOSE <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="box"><strong>Find the best predictive model out of a parameterized set, via cross-validation.</strong></div>

<h2><a name="_synopsis"></a>SYNOPSIS <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="box"><strong>function [model,stats] = utl_searchmodel(varargin) </strong></div>

<h2><a name="_description"></a>DESCRIPTION <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="fragment"><pre class="comment"> Find the best predictive model out of a parameterized set, via cross-validation.
 [Model,Stats] = utl_searchmodel(Data, Arguments...)

 When a predictive model is learned from some data, several of its key parameters can usually be 
 efficiently optimized given the data (namely, if their solutions are available in closed form, or 
 if they can be found by solving a well-behaved optimization problem). Some parameters, however,
 usually remain, which can not be optimized by the given learning function. If their optimal values
 are unknown but assumed to lie in a small set of possibilities, a general-purpose approach to find 
 them as well, is exhaustive search over all possibilities, coupled with a cross-validation to 
 assess the predictive performance for each possibility on the available data. 

 This function performs this task, and can jointly optimize all unknown parameters of a learning
 function. It requires a data set and (because a cross-validation is implicitly performed) all
 parameters that would be required to apply utl_crossval to the given data. The function whose
 parameters shall be optimized is the 'trainer' (i.e., model learning) function. For any of its
 parameters which has multiple possibilities (over which to optimize), these possibilities can be
 specified using the same syntax as in the grid searching function utl_gridsearch (where the 
 default here is to specify them via search() clauses).

 In:
   Data :   some data that can be partitioned using index sets

   Arguments : mandatory arguments:
               'trainer': training function; receives a partition of the data (as produced by 
                          the partitioner), some further arguments (as specified in args), and
                          returns a model (of any kind)

               'tester' : testing function; receives a model (as produced by the trainer) and a 
                          partition of the data (as produced by the partitioner), and returns a
                          prediction for every index of the input data, in a format allowed by
                          ml_predict

               'args': arguments to the training function, cell array (default: empty)
                       specified as in utl_gridsearch (format controlled via argform)

               optional arguments (same as in utl_crossval, listed below for convenience)
               'scheme': cross-validation scheme, can be one of the following: (default: 10)
                 * 0: skip CV, return NaN and empty statistics
                 * k: k-fold randomized CV (or, if 0&lt;k&lt;1, k-holdhout CV)
                 * [r k]: r-time repartitioned k-fold randomized CV (or, if 0&lt;k&lt;1, 
                   k-holdout CV (with k a fraction))
                 * 'loo': leave-one-out CV
                 * {'chron', k} or {'block', k}: k-fold chronological/blockwise CV
                 * {'chron', k, m} or {'block', k, m}: k-fold chronological/blockwise CV with 
                   m indices margin width (between training and test set)

               'partitioner': partitioning function for the data, receives three parameters: 
                              (data, index vector, packed trainer args OR model)
                               * if the index vector is empty, should return the highest index 
                                 in the data
                               * otherwise, it should return data subindexed by the index vector
                              default: provides support for cell arrays, numeric arrays, struct 
                                       arrays and {Data,Target} cell arrays
                              note: the third parameter is for convenience and may optionally be 
                                    taken into account; trainer args are passed packed into a cell
                                    array for both index set generation and computation of the
                                    training partition(s), and the model is passed for the
                                    computation of testing partitions

               'target': a function to derive the target variable from a partition of the data (as 
                         produced by the partitioner), for evaluation; the allowed format is
                         anything that may be output by ml_predict default: provides support for
                         {Data,Target} cell arrays

               'metric': metric to be employed, applied both in each fold and the aggregated data 
                         over all folds
                          * function handle: a custom, user-supplied loss function; receives target 
                            data in the first argument and prediction data in the second argument;
                            each can be in any format that can be produced by ml_predict (but can
                            be expected to be mutually consistent). shall return a real number
                            indicating the summary metric over all data, and optionally additional
                            statistics in a struct
                          * string: use ml_calcloss, with 'metric' determining the loss type
                          * default: use 'mcr','mse','nll','kld', depending on supplied target &amp; 
                            prediction data formats

               'argform': format of the argument ranges, either 'direct' or 'clauses'
                          (default: 'clauses')
                           'direct': search ranges are directly specified as arrays
                           'clauses': search ranges are specified using the search() clause

               'forcestats': enforce a cross-validation to obtain stats, even when no search is 
                             necessary (default: 0)

               further arguments (same as in utl_crossval)
               'cache_fold_results' : whether to cache the per-fold results. (default: false)

               'only_cached_results' : load only results that are in the cache. (default: false)

               'tolerate_exceptions' : tolerate exceptions during training step. (default: false)

               further arguments (same as in par_beginschedule, listed below for convenience)
               'engine_gs': the parallelization engine to be used for the grid search
                            (default: 'local')

               'engine_ncv': the parallelization engine to be used for the nested cross-validation
                             (default: 'global')

               'pool'     : node pool to be used for parallelization, when using the BLS scheduler
                            (default: 'global')

               'policy'   : scheduling policy to be used, when using the BLS scheduler
                            (default: 'global')

 Out:
   Model : the best model, as determined through cross-validation and and grid search 
           w.r.t. to a measure of the overall performance of the trainer/tester combination

   Stats : additional statistics over all tested argument combinations, as produced by the metric

 See also:
   <a href="utl_crossval.html" class="code" title="function [measure,stats] = utl_crossval(varargin)">utl_crossval</a>, <a href="utl_gridsearch.html" class="code" title="function [minidx, inputs, outputs] = utl_gridsearch(arg1, varargin)">utl_gridsearch</a>, <a href="utl_nested_crossval.html" class="code" title="function [measure,stats] = utl_nested_crossval(varargin)">utl_nested_crossval</a>

 Example:
   % assuming a feature matrix called trials and a label vector called targets, sized as:
   %  trials: [NxF] array of training instances
   %  targets: [Nx1] array of labels

   % find the best-performing SVM classifier on the data (here: ignoring the kernel scale parameter)
   [model,stats] = utl_searchmodel({trials,targets}, 'args',{{'svm' search(2.^(-5:2:15))}})

                                Christian Kothe, Swartz Center for Computational Neuroscience, UCSD
                                2010-04-22</pre></div>

<!-- crossreference -->
<h2><a name="_cross"></a>CROSS-REFERENCE INFORMATION <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
This function calls:
<ul style="list-style-image:url(../../matlabicon.gif)">

<li><a href="utl_crossval.html" class="code" title="function [measure,stats] = utl_crossval(varargin)">utl_crossval</a>	Run a generic cross-validation over indexable data.</li>
<li><a href="utl_gridsearch.html" class="code" title="function [minidx, inputs, outputs] = utl_gridsearch(arg1, varargin)">utl_gridsearch</a>	Exhaustive search over multiple possible arguments to a function.</li>
</ul>
This function is called by:
<ul style="list-style-image:url(../../matlabicon.gif)">

<li><a href="utl_nested_crossval.html" class="code" title="function [measure,stats] = utl_nested_crossval(varargin)">utl_nested_crossval</a>	Run a generic nested cross-validation over indexable data.</li>
</ul>
<!-- crossreference -->






<h2><a name="_source"></a>SOURCE CODE <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="fragment"><pre>0001 <a name="_sub0" href="#_subfunctions" class="code">function [model,stats] = utl_searchmodel(varargin)</a>
0002 <span class="comment">% Find the best predictive model out of a parameterized set, via cross-validation.</span>
0003 <span class="comment">% [Model,Stats] = utl_searchmodel(Data, Arguments...)</span>
0004 <span class="comment">%</span>
0005 <span class="comment">% When a predictive model is learned from some data, several of its key parameters can usually be</span>
0006 <span class="comment">% efficiently optimized given the data (namely, if their solutions are available in closed form, or</span>
0007 <span class="comment">% if they can be found by solving a well-behaved optimization problem). Some parameters, however,</span>
0008 <span class="comment">% usually remain, which can not be optimized by the given learning function. If their optimal values</span>
0009 <span class="comment">% are unknown but assumed to lie in a small set of possibilities, a general-purpose approach to find</span>
0010 <span class="comment">% them as well, is exhaustive search over all possibilities, coupled with a cross-validation to</span>
0011 <span class="comment">% assess the predictive performance for each possibility on the available data.</span>
0012 <span class="comment">%</span>
0013 <span class="comment">% This function performs this task, and can jointly optimize all unknown parameters of a learning</span>
0014 <span class="comment">% function. It requires a data set and (because a cross-validation is implicitly performed) all</span>
0015 <span class="comment">% parameters that would be required to apply utl_crossval to the given data. The function whose</span>
0016 <span class="comment">% parameters shall be optimized is the 'trainer' (i.e., model learning) function. For any of its</span>
0017 <span class="comment">% parameters which has multiple possibilities (over which to optimize), these possibilities can be</span>
0018 <span class="comment">% specified using the same syntax as in the grid searching function utl_gridsearch (where the</span>
0019 <span class="comment">% default here is to specify them via search() clauses).</span>
0020 <span class="comment">%</span>
0021 <span class="comment">% In:</span>
0022 <span class="comment">%   Data :   some data that can be partitioned using index sets</span>
0023 <span class="comment">%</span>
0024 <span class="comment">%   Arguments : mandatory arguments:</span>
0025 <span class="comment">%               'trainer': training function; receives a partition of the data (as produced by</span>
0026 <span class="comment">%                          the partitioner), some further arguments (as specified in args), and</span>
0027 <span class="comment">%                          returns a model (of any kind)</span>
0028 <span class="comment">%</span>
0029 <span class="comment">%               'tester' : testing function; receives a model (as produced by the trainer) and a</span>
0030 <span class="comment">%                          partition of the data (as produced by the partitioner), and returns a</span>
0031 <span class="comment">%                          prediction for every index of the input data, in a format allowed by</span>
0032 <span class="comment">%                          ml_predict</span>
0033 <span class="comment">%</span>
0034 <span class="comment">%               'args': arguments to the training function, cell array (default: empty)</span>
0035 <span class="comment">%                       specified as in utl_gridsearch (format controlled via argform)</span>
0036 <span class="comment">%</span>
0037 <span class="comment">%               optional arguments (same as in utl_crossval, listed below for convenience)</span>
0038 <span class="comment">%               'scheme': cross-validation scheme, can be one of the following: (default: 10)</span>
0039 <span class="comment">%                 * 0: skip CV, return NaN and empty statistics</span>
0040 <span class="comment">%                 * k: k-fold randomized CV (or, if 0&lt;k&lt;1, k-holdhout CV)</span>
0041 <span class="comment">%                 * [r k]: r-time repartitioned k-fold randomized CV (or, if 0&lt;k&lt;1,</span>
0042 <span class="comment">%                   k-holdout CV (with k a fraction))</span>
0043 <span class="comment">%                 * 'loo': leave-one-out CV</span>
0044 <span class="comment">%                 * {'chron', k} or {'block', k}: k-fold chronological/blockwise CV</span>
0045 <span class="comment">%                 * {'chron', k, m} or {'block', k, m}: k-fold chronological/blockwise CV with</span>
0046 <span class="comment">%                   m indices margin width (between training and test set)</span>
0047 <span class="comment">%</span>
0048 <span class="comment">%               'partitioner': partitioning function for the data, receives three parameters:</span>
0049 <span class="comment">%                              (data, index vector, packed trainer args OR model)</span>
0050 <span class="comment">%                               * if the index vector is empty, should return the highest index</span>
0051 <span class="comment">%                                 in the data</span>
0052 <span class="comment">%                               * otherwise, it should return data subindexed by the index vector</span>
0053 <span class="comment">%                              default: provides support for cell arrays, numeric arrays, struct</span>
0054 <span class="comment">%                                       arrays and {Data,Target} cell arrays</span>
0055 <span class="comment">%                              note: the third parameter is for convenience and may optionally be</span>
0056 <span class="comment">%                                    taken into account; trainer args are passed packed into a cell</span>
0057 <span class="comment">%                                    array for both index set generation and computation of the</span>
0058 <span class="comment">%                                    training partition(s), and the model is passed for the</span>
0059 <span class="comment">%                                    computation of testing partitions</span>
0060 <span class="comment">%</span>
0061 <span class="comment">%               'target': a function to derive the target variable from a partition of the data (as</span>
0062 <span class="comment">%                         produced by the partitioner), for evaluation; the allowed format is</span>
0063 <span class="comment">%                         anything that may be output by ml_predict default: provides support for</span>
0064 <span class="comment">%                         {Data,Target} cell arrays</span>
0065 <span class="comment">%</span>
0066 <span class="comment">%               'metric': metric to be employed, applied both in each fold and the aggregated data</span>
0067 <span class="comment">%                         over all folds</span>
0068 <span class="comment">%                          * function handle: a custom, user-supplied loss function; receives target</span>
0069 <span class="comment">%                            data in the first argument and prediction data in the second argument;</span>
0070 <span class="comment">%                            each can be in any format that can be produced by ml_predict (but can</span>
0071 <span class="comment">%                            be expected to be mutually consistent). shall return a real number</span>
0072 <span class="comment">%                            indicating the summary metric over all data, and optionally additional</span>
0073 <span class="comment">%                            statistics in a struct</span>
0074 <span class="comment">%                          * string: use ml_calcloss, with 'metric' determining the loss type</span>
0075 <span class="comment">%                          * default: use 'mcr','mse','nll','kld', depending on supplied target &amp;</span>
0076 <span class="comment">%                            prediction data formats</span>
0077 <span class="comment">%</span>
0078 <span class="comment">%               'argform': format of the argument ranges, either 'direct' or 'clauses'</span>
0079 <span class="comment">%                          (default: 'clauses')</span>
0080 <span class="comment">%                           'direct': search ranges are directly specified as arrays</span>
0081 <span class="comment">%                           'clauses': search ranges are specified using the search() clause</span>
0082 <span class="comment">%</span>
0083 <span class="comment">%               'forcestats': enforce a cross-validation to obtain stats, even when no search is</span>
0084 <span class="comment">%                             necessary (default: 0)</span>
0085 <span class="comment">%</span>
0086 <span class="comment">%               further arguments (same as in utl_crossval)</span>
0087 <span class="comment">%               'cache_fold_results' : whether to cache the per-fold results. (default: false)</span>
0088 <span class="comment">%</span>
0089 <span class="comment">%               'only_cached_results' : load only results that are in the cache. (default: false)</span>
0090 <span class="comment">%</span>
0091 <span class="comment">%               'tolerate_exceptions' : tolerate exceptions during training step. (default: false)</span>
0092 <span class="comment">%</span>
0093 <span class="comment">%               further arguments (same as in par_beginschedule, listed below for convenience)</span>
0094 <span class="comment">%               'engine_gs': the parallelization engine to be used for the grid search</span>
0095 <span class="comment">%                            (default: 'local')</span>
0096 <span class="comment">%</span>
0097 <span class="comment">%               'engine_ncv': the parallelization engine to be used for the nested cross-validation</span>
0098 <span class="comment">%                             (default: 'global')</span>
0099 <span class="comment">%</span>
0100 <span class="comment">%               'pool'     : node pool to be used for parallelization, when using the BLS scheduler</span>
0101 <span class="comment">%                            (default: 'global')</span>
0102 <span class="comment">%</span>
0103 <span class="comment">%               'policy'   : scheduling policy to be used, when using the BLS scheduler</span>
0104 <span class="comment">%                            (default: 'global')</span>
0105 <span class="comment">%</span>
0106 <span class="comment">% Out:</span>
0107 <span class="comment">%   Model : the best model, as determined through cross-validation and and grid search</span>
0108 <span class="comment">%           w.r.t. to a measure of the overall performance of the trainer/tester combination</span>
0109 <span class="comment">%</span>
0110 <span class="comment">%   Stats : additional statistics over all tested argument combinations, as produced by the metric</span>
0111 <span class="comment">%</span>
0112 <span class="comment">% See also:</span>
0113 <span class="comment">%   utl_crossval, utl_gridsearch, utl_nested_crossval</span>
0114 <span class="comment">%</span>
0115 <span class="comment">% Example:</span>
0116 <span class="comment">%   % assuming a feature matrix called trials and a label vector called targets, sized as:</span>
0117 <span class="comment">%   %  trials: [NxF] array of training instances</span>
0118 <span class="comment">%   %  targets: [Nx1] array of labels</span>
0119 <span class="comment">%</span>
0120 <span class="comment">%   % find the best-performing SVM classifier on the data (here: ignoring the kernel scale parameter)</span>
0121 <span class="comment">%   [model,stats] = utl_searchmodel({trials,targets}, 'args',{{'svm' search(2.^(-5:2:15))}})</span>
0122 <span class="comment">%</span>
0123 <span class="comment">%                                Christian Kothe, Swartz Center for Computational Neuroscience, UCSD</span>
0124 <span class="comment">%                                2010-04-22</span>
0125 dp;
0126 
0127 <span class="comment">% parse arguments</span>
0128 opts = arg_define(0:1,varargin, <span class="keyword">...</span>
0129     <span class="keyword">...</span><span class="comment"> % training data</span>
0130     arg_norep({<span class="string">'data'</span>,<span class="string">'Data'</span>},[],[],<span class="string">'Data that can be partitioned using index sets. Such as, for example, {X,y} with X being the [NxF] training data and y being the [Nx1] labels (N=#trials, F=#features).'</span>), <span class="keyword">...</span>
0131     <span class="keyword">...</span><span class="comment"> % method to use and its arguments</span>
0132     arg({<span class="string">'args'</span>,<span class="string">'TrainingArguments'</span>},{},[],<span class="string">'Arguments to the training function. Packed in a cell array. Search ranges are defined according to ArgumentFormat; see also utl_gridsearch for additional clarification on this. Note: if using the default trainer/tester functions, args must at least specify the learning function to be used, optionally followed by arguments to that learning function, e.g. {''lda''} for linear discriminant analysis or {''logreg'',''lambda'',0.1} for logistic regression with ''lambda'',0.1 passed in as user parameters (see ml_train* functions for options).'</span>,<span class="string">'type'</span>,<span class="string">'expression'</span>), <span class="keyword">...</span>
0133     arg({<span class="string">'trainer'</span>,<span class="string">'TrainingFunction'</span>},<span class="string">'@ml_train'</span>,[],<span class="string">'Training function. Receives a partition of the data (as produced by the specified partitioner), possibly some further arguments as specified in args, and returns a model (of any kind).'</span>,<span class="string">'type'</span>,<span class="string">'expression'</span>), <span class="keyword">...</span>
0134     arg({<span class="string">'tester'</span>,<span class="string">'PredictionFunction'</span>},<span class="string">'@utl_default_predict'</span>,[],<span class="string">'Prediction function. Receives a partition of the data (as produced by the partitioner) and a model (as produced by the trainer), and returns a prediction for every index of the input data, in one of the output formats permitted by ml_predict.'</span>,<span class="string">'type'</span>,<span class="string">'expression'</span>), <span class="keyword">...</span>
0135     <span class="keyword">...</span><span class="comment"> % nested cross-validation parameters</span>
0136     arg({<span class="string">'scheme'</span>,<span class="string">'EvaluationScheme'</span>},10,[],<span class="string">'Cross-validation scheme. Defines what parts of the data shall be used for training or testing in each fold. Supports many different formats, see documentation.'</span>,<span class="string">'type'</span>,<span class="string">'expression'</span>), <span class="keyword">...</span>
0137     arg({<span class="string">'metric'</span>,<span class="string">'EvaluationMetric'</span>},<span class="string">'auto'</span>,{<span class="string">'auto'</span>,<span class="string">'mcr'</span>,<span class="string">'auc'</span>,<span class="string">'mse'</span>,<span class="string">'medse'</span>,<span class="string">'smse'</span>,<span class="string">'mae'</span>,<span class="string">'medae'</span>,<span class="string">'smae'</span>,<span class="string">'smedae'</span>,<span class="string">'max'</span>,<span class="string">'sign'</span>,<span class="string">'rms'</span>,<span class="string">'bias'</span>,<span class="string">'kld'</span>,<span class="string">'nll'</span>,<span class="string">'cond_entropy'</span>,<span class="string">'cross_entropy'</span>,<span class="string">'f_measure'</span>},<span class="string">'Evaluation metric. Loss measure employed to measure the quality of predictions on a test partition given its known target values; applied both to results in each fold and results aggregated over all folds. Can be either a predefined metric supported by ml_calcloss, or a custom function handle which receives an array of target values in the first argument and an array of predictions in the second argument; each can be in any format that can be produced by ml_predict (but can be expected to be mutually consistent). Shall return a real number indicating the summary metric over all data, and optionally additional statistics in a second output struct.'</span>,<span class="string">'typecheck'</span>,false), <span class="keyword">...</span>
0138     arg({<span class="string">'repeatable'</span>,<span class="string">'RepeatableResults'</span>},1,[],<span class="string">'Produce repeatable (vs. randomized) results. If nonzero, the value is taken as the random seed to use for the performed calculation. This way, different numbers (aside from 0) give different repeatable runs.'</span>), <span class="keyword">...</span>
0139     <span class="keyword">...</span><span class="comment"> % support for custom data representations</span>
0140     arg({<span class="string">'target'</span>,<span class="string">'TargetFunction'</span>},<span class="string">'@utl_default_target'</span>,[],<span class="string">'Target extraction function. A function to derive the target variable from a partition of the data (as produced by the partitioner), for evaluation; the allowed format is anything that may be output by ml_predict.'</span>,<span class="string">'type'</span>,<span class="string">'expression'</span>), <span class="keyword">...</span>
0141     arg({<span class="string">'partitioner'</span>,<span class="string">'PartitioningFunction'</span>},<span class="string">'@utl_default_partitioner'</span>,[],<span class="string">'Partitioning function. See documentation for the function contract.'</span>,<span class="string">'type'</span>,<span class="string">'expression'</span>), <span class="keyword">...</span>
0142     <span class="keyword">...</span><span class="comment"> % parallel computing settings</span>
0143     arg({<span class="string">'engine_gs'</span>,<span class="string">'ParallelEngineGS'</span>},<span class="string">'global'</span>,{<span class="string">'global'</span>,<span class="string">'local'</span>,<span class="string">'BLS'</span>,<span class="string">'Reference'</span>,<span class="string">'ParallelComputingToolbox'</span>}, <span class="string">'Parallel engine for grid search. This can either be one of the supported parallel engines (BLS for BCILAB Scheduler, Reference for a local reference implementation, and ParallelComputingToolbox for a PCT-based implementation), or local to skip parallelization altogether, or global to select the currently globally selected setting (in the global tracking variable).'</span>), <span class="keyword">...</span>
0144     arg({<span class="string">'engine_ncv'</span>,<span class="string">'ParallelEngineNCV'</span>},<span class="string">'global'</span>,{<span class="string">'global'</span>,<span class="string">'local'</span>,<span class="string">'BLS'</span>,<span class="string">'Reference'</span>,<span class="string">'ParallelComputingToolbox'</span>}, <span class="string">'Parallel engine for cross-validation. This can either be one of the supported parallel engines (BLS for BCILAB Scheduler, Reference for a local reference implementation, and ParallelComputingToolbox for a PCT-based implementation), or local to skip parallelization altogether, or global to select the currently globally selected setting (in the global tracking variable).'</span>), <span class="keyword">...</span>
0145     arg({<span class="string">'pool'</span>,<span class="string">'WorkerPool'</span>},<span class="string">'global'</span>,[], <span class="string">'Worker pool to use. This is typically a cell array, but can also be the string ''gobal'', which stands for the currently globally set up worker pool (see global tracking variable).'</span>,<span class="string">'type'</span>,<span class="string">'expression'</span>), <span class="keyword">...</span>
0146     arg({<span class="string">'policy'</span>,<span class="string">'ReschedulingPolicy'</span>},<span class="string">'global'</span>,[], <span class="string">'Rescheduling policy. This is the name of the rescheduling policy function that controls if and when tasks are being rescheduled. If set to global, the current global setting will be used.'</span>), <span class="keyword">...</span><span class="comment">    </span>
0147     <span class="keyword">...</span><span class="comment"> % misc arguments</span>
0148     arg({<span class="string">'argform'</span>,<span class="string">'ArgumentFormat'</span>},<span class="string">'clauses'</span>,{<span class="string">'clauses'</span>,<span class="string">'direct'</span>},<span class="string">'Argument search range format. If set to clauses, search ranges for individual arguments can be given using the search() expression; if set to direct, a cell array is expected each of whose elements is a cell array that represents a particular parameter set to try for the training function.'</span>), <span class="keyword">...</span>
0149     arg({<span class="string">'forcestats'</span>,<span class="string">'ForceStatistics'</span>},0,[],<span class="string">'Enforce a cross-validation to obtain stats. Even when no search is required.'</span>), <span class="keyword">...</span>
0150     arg({<span class="string">'cache_fold_results'</span>,<span class="string">'CacheFoldResults'</span>},false,[],<span class="string">'Whether to cache the per-fold results. This is meant to be used when running very long-running computations on machines that crash frequently enough that partial results need to be saved. In this case, any previously computed results will be loaded from disk.'</span>), <span class="keyword">...</span>
0151     arg({<span class="string">'only_cached_results'</span>,<span class="string">'OnlyCachedResults'</span>},false,[],<span class="string">'Load only results that are in the cache. This will not run any computations (aside from pre-checks, that can be disabled by setting NoPrechecks to true).'</span>), <span class="keyword">...</span>
0152     arg({<span class="string">'no_prechecks'</span>,<span class="string">'NoPrechecks'</span>},false,[],<span class="string">'Skip pre-checks that access the data. This can save some time when it would take very long to load the data, especially when performing parallel computation.'</span>), <span class="keyword">...</span>
0153     arg({<span class="string">'tolerate_exceptions'</span>,<span class="string">'TolerateExceptions'</span>},false,[],<span class="string">'Tolerate exceptions during training. If this happens, folds where the training function yielded errors will be skipped.'</span>), <span class="keyword">...</span>
0154     arg({<span class="string">'collect_models'</span>,<span class="string">'CollectModels'</span>},false,[],<span class="string">'Collect models per fold. Note that this increases the amount of data returned.'</span>));
0155 
0156 <span class="comment">% if there are parameters to be searched...</span>
0157 <span class="keyword">if</span> opts.forcestats || is_needing_search(opts.argform,opts.args)
0158     
0159     <span class="comment">% the nested cross-validation (utl_crossval) receives a specific subset of our arguments</span>
0160     nestedcv_opts = hlp_struct2varargin(opts,<span class="string">'suppress'</span>,{<span class="string">'engine_gs'</span>,<span class="string">'forcestats'</span>,<span class="string">'args'</span>,<span class="string">'argform'</span>},<span class="string">'rewrite'</span>,{<span class="string">'engine_ncv'</span>,<span class="string">'engine_cv'</span>});
0161 
0162     <span class="comment">% the objective function of our search is utl_crossval with the above-defined options; plus, it</span>
0163     <span class="comment">% has free arguments that are passed into the cross-validation as the 'args' parameter (i.e.,</span>
0164     <span class="comment">% the arguments that it passes into its 'trainer' function)</span>
0165     objfun = @(varargin) <a href="utl_crossval.html" class="code" title="function [measure,stats] = utl_crossval(varargin)">utl_crossval</a>(nestedcv_opts{:}, <span class="string">'args'</span>,varargin);
0166     
0167     <span class="comment">% the grid search receives the above-defined objective function and a subset of our arguments</span>
0168     search_opts = {<span class="string">'argform'</span>,opts.argform, <span class="string">'engine_gs'</span>,opts.engine_gs, <span class="string">'policy'</span>,opts.policy, <span class="keyword">...</span>
0169         <span class="string">'pool'</span>,opts.pool, <span class="string">'func'</span>,objfun};
0170     
0171     <span class="comment">% now execute the grid search over every argument combination specified in opts.args</span>
0172     [stats.bestidx,stats.inputs,stats.outputs] = <a href="utl_gridsearch.html" class="code" title="function [minidx, inputs, outputs] = utl_gridsearch(arg1, varargin)">utl_gridsearch</a>(search_opts, opts.args{:});
0173     
0174 <span class="keyword">else</span>
0175     
0176     <span class="comment">% otherwise produce dummy stats if neither necessary nor forced</span>
0177     stats = struct(<span class="string">'bestidx'</span>,1, <span class="string">'inputs'</span>,{{opts.args}}, <span class="string">'outputs'</span>,{{NaN,struct()}});
0178     
0179 <span class="keyword">end</span>
0180 
0181 <span class="comment">% finally, using the best args, send the input data through the training function &amp; compute a model</span>
0182 bestargs = stats.inputs{stats.bestidx};
0183 model = opts.trainer(opts.data,bestargs{:});</pre></div>

<hr><address>Generated on Wed 19-Aug-2015 18:06:23 by <strong><a href="http://www.artefact.tk/software/matlab/m2html/" title="Matlab Documentation in HTML">m2html</a></strong> &copy; 2005</address>
</body>
</html>